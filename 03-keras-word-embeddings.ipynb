{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/fchollet/deep-learning-with-python-notebooks/blob/master/LICENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:23:40.684278Z",
     "start_time": "2018-04-25T15:23:39.821167Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sai/code/personal/nlp-tutorials-notes/.env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to obtain word embeddings:\n",
    "\n",
    "1. Learn word embeddings jointly with the main task you care about (e.g. document classification or sentiment prediction). In this setup, you would start with random word vectors, then learn your word vectors in the same way that you learn the weights of a neural network.\n",
    "2. Load into your model word embeddings that were pre-computed using a different machine learning task than the one you are trying to solve. These are called \"pre-trained word embeddings\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning word embeddings with the Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:23:50.846410Z",
     "start_time": "2018-04-25T15:23:50.839736Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:23:51.194091Z",
     "start_time": "2018-04-25T15:23:51.113468Z"
    }
   },
   "outputs": [],
   "source": [
    "# the embedding layer takes at least two arguments\n",
    "# the number of possible tokens, here (1000) (1+maximum word index)\n",
    "# and the dimensionality of the embeddings, here 64\n",
    "embedding_layer = Embedding(1000, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The Embedding layer is best understood as a dictionary mapping integer indices (which stand for specific words) to dense vectors.\n",
    "- The Embedding layer takes as input a 2D tensor of integers, of shape (samples, sequence_length), where each entry is a sequence of integers\n",
    "- It can embed sequences of variable lengths\n",
    "- All sequences in a batach must have the same length\n",
    "- This layer returns a 3D floating tensor, of shape (samples, sequence_length, embedding_dimensionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB movie review sentiment prediciton task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:23:52.166294Z",
     "start_time": "2018-04-25T15:23:52.160653Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:23:53.141404Z",
     "start_time": "2018-04-25T15:23:53.137602Z"
    }
   },
   "outputs": [],
   "source": [
    "# number of words to consider as features\n",
    "max_features = 10000\n",
    "# cut texts after this number of words\n",
    "maxlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:09.471050Z",
     "start_time": "2018-04-25T15:23:53.608577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 12s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:09.475764Z",
     "start_time": "2018-04-25T15:24:09.472534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:09.596744Z",
     "start_time": "2018-04-25T15:24:09.477516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:09.996506Z",
     "start_time": "2018-04-25T15:24:09.598563Z"
    }
   },
   "outputs": [],
   "source": [
    "# this turns our lists of integers into a 2D integer tensor of shape (samples, maxlen)\n",
    "X_train = preprocessing.sequence.pad_sequences(X_train, maxlen = maxlen)\n",
    "X_test  = preprocessing.sequence.pad_sequences(X_test, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:10.037801Z",
     "start_time": "2018-04-25T15:24:09.998064Z"
    }
   },
   "outputs": [],
   "source": [
    "?preprocessing.sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:10.125116Z",
     "start_time": "2018-04-25T15:24:10.040954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:10.218263Z",
     "start_time": "2018-04-25T15:24:10.127326Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  65,   16,   38, ...,   19,  178,   32],\n",
       "       [  23,    4, 1690, ...,   16,  145,   95],\n",
       "       [1352,   13,  191, ...,    7,  129,  113],\n",
       "       ...,\n",
       "       [  11, 1818, 7561, ...,    4, 3586,    2],\n",
       "       [  92,  401,  728, ...,   12,    9,   23],\n",
       "       [ 764,   40,    4, ...,  204,  131,    9]], dtype=int32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:10.307095Z",
     "start_time": "2018-04-25T15:24:10.221405Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:10.760288Z",
     "start_time": "2018-04-25T15:24:10.308596Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 20, 8)             80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 161       \n",
      "=================================================================\n",
      "Total params: 80,161\n",
      "Trainable params: 80,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(10000, 8, input_length = maxlen))\n",
    "# our activations have shape (samples, maxlen, 8) now\n",
    "model.add(Flatten())\n",
    "# shape is (samples, maxlen*8)\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy', metrics = ['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:24:23.717588Z",
     "start_time": "2018-04-25T15:24:15.760343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.6759 - acc: 0.6043 - val_loss: 0.6398 - val_acc: 0.6810\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.5657 - acc: 0.7428 - val_loss: 0.5467 - val_acc: 0.7206\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.4752 - acc: 0.7808 - val_loss: 0.5113 - val_acc: 0.7384\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.4263 - acc: 0.8079 - val_loss: 0.5008 - val_acc: 0.7454\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.3930 - acc: 0.8257 - val_loss: 0.4981 - val_acc: 0.7540\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.3668 - acc: 0.8395 - val_loss: 0.5013 - val_acc: 0.7534\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.3435 - acc: 0.8534 - val_loss: 0.5051 - val_acc: 0.7518\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.3223 - acc: 0.8658 - val_loss: 0.5132 - val_acc: 0.7486\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.3022 - acc: 0.8765 - val_loss: 0.5213 - val_acc: 0.7492\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.2839 - acc: 0.8860 - val_loss: 0.5302 - val_acc: 0.7466\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                   epochs = 10, batch_size = 32, \n",
    "                   validation_split = 0.2, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download imdb raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:39:56.806705Z",
     "start_time": "2018-04-25T15:39:56.223891Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "imdb_dir = './data/aclImdb'\n",
    "train_dir = os.path.join(imdb_dir, 'train')\n",
    "\n",
    "labels = []\n",
    "texts = []\n",
    "\n",
    "for label_type in ['neg', 'pos']:\n",
    "    dir_name = os.path.join(train_dir, label_type)\n",
    "    for fname in os.listdir(dir_name):\n",
    "        if fname[-4:] == '.txt':\n",
    "            f = open(os.path.join(dir_name, fname))\n",
    "            texts.append(f.read())\n",
    "            f.close()\n",
    "            if label_type == 'neg':\n",
    "                labels.append(0)\n",
    "            else:\n",
    "                labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:39:57.237672Z",
     "start_time": "2018-04-25T15:39:57.230636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:39:59.575513Z",
     "start_time": "2018-04-25T15:39:59.572253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love Alec Guinness. And that\\'s saying a lot after this film. Actually, he is not bad in it. He just seems to stand aside, be urbane and his usual delightful self, but invest nada. It is obvious the girl he is matched with is a featherweight, even as an inexperienced young French girl. Sir Alec wouldn\\'t have chosen her when he was young and very obviously isn\\'t too happy about it now.<br /><br />The interesting character is the brooding brother of the odd \"Suzanne\", another twit. \"Donald\" aspires to be a French Heathcliffe and I waited in vain for the source of his mystery. What deep dark secret was he hiding behind that forehead? Was he in love with the father\\'s mistress? Why did he jerk Suzanne\\'s hair when she plotted to bring the disparate parts of this turkey together on the country estate? Or perhaps he had simply had enough of her obnoxious acting.<br /><br />The film would have been charming with Guiness and the \"older woman\" reminiscing and seeing Paris together. THAT would have been a great story! Two lovely experienced people in a beautiful city after the destruction of World War II. Why didn\\'t somebody come up with that? I suggest watching Alec Guiness in \"The Card\", a little known but worthwhile film.',\n",
       " \"Dysfunctional family goes home for the holidays and murder and mayhem result. Violent sexy Milligan at his most home made. Little better than a home movie (as much of Milligans films are) this is a trip into depravity 1960's style. Notable for the copious nudity and sex this film is neither sexy nor gruesome, playing now more as quaint.(though decidedly r rated). The film suffers from its uneven cast and from the cheapness of the production.(No one was ever sure where the money went on his movies since he was always broke). Its a bad bad movie thats not worth seeing except as a Milligan completeist or because its got some good looking people fooling around.\",\n",
       " 'There is an awful lot wrong with this picture, beginning with a script that is both obvious and redundant. Courtney Cox plays a comic book artist who escapes to a small desert town after being raped twice in the big city. She immediately is stalked by a local who appears quite unhinged (Craig Sheffer), and who seems to be attempting a third rate Mickey Rourke imitation. D.B. Sweeny is a local cop, who is supposedly there to protect and serve. Meanwhile, the script manipulates the audience as to who\\'s really the good guy? Logic flies out the window after the first ten minutes and never returns, and there are more unanswered questions than there should be. If you think \"Blue Desert\" might be saved by the wonderful Philip Baker Hall, you will be disappointed. His part is insignificant, just like the entire movie. - MERK',\n",
       " 'It was 1 a.m. in the morning and I had nothing else to do. Don\\'t judge me... please.<br /><br />We\\'re back in time during the Spanish settlements. A group have made their way onto an island. It doesn\\'t take too long before they encounter a large \"reptile\", which gobbles up their horse. Soon they\\'re captured by the natives and in order to gain freedom they must kill the \"reptile gods.\" THE CG sucks; it reminds me of the CG of early console video games. The encounters were lame. The only positive thing I have to say about this was the hottie native running around in a skimpy outfit. Otherwise it\\'s just a middling effort.',\n",
       " 'I give this marriage 3 years and thats stretching it. Adrianne Curry is fouled mouth, spoiled, controlling, loud, and her bi sexual past makes me laugh. She tells Chris he has an image to protect and must avoid strip clubs. He married her. Chris has low self esteem and from a different time warp. I have nothing against Adrianne Curry but this combination is not gonna have a happy ever after ending. Her mother said he was an old rooster and thinks this is his last attempt to recapture his youth. Here 2 very good people who are gonna end up in a nasty divorce. I don\\'t think his old \" Brady Family\" is gonna fit into his new life. I see them being shut out. Chris said his friends were more important than his family. The supported him and was there for him.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:40:02.363176Z",
     "start_time": "2018-04-25T15:40:02.356748Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:40:03.082432Z",
     "start_time": "2018-04-25T15:40:03.079999Z"
    }
   },
   "outputs": [],
   "source": [
    "maxlen = 100  # We will cut reviews after 100 words\n",
    "training_samples = 200  # We will be training on 200 samples\n",
    "validation_samples = 10000  # We will be validating on 10000 samples\n",
    "max_words = 10000  # We will only consider the top 10,000 words in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:40:10.307988Z",
     "start_time": "2018-04-25T15:40:03.498829Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:40:10.326613Z",
     "start_time": "2018-04-25T15:40:10.309243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'and': 2,\n",
       " 'a': 3,\n",
       " 'of': 4,\n",
       " 'to': 5,\n",
       " 'is': 6,\n",
       " 'br': 7,\n",
       " 'in': 8,\n",
       " 'it': 9,\n",
       " 'i': 10,\n",
       " 'this': 11,\n",
       " 'that': 12,\n",
       " 'was': 13,\n",
       " 'as': 14,\n",
       " 'for': 15,\n",
       " 'with': 16,\n",
       " 'movie': 17,\n",
       " 'but': 18,\n",
       " 'film': 19,\n",
       " 'on': 20,\n",
       " 'not': 21,\n",
       " 'you': 22,\n",
       " 'are': 23,\n",
       " 'his': 24,\n",
       " 'have': 25,\n",
       " 'he': 26,\n",
       " 'be': 27,\n",
       " 'one': 28,\n",
       " 'all': 29,\n",
       " 'at': 30,\n",
       " 'by': 31,\n",
       " 'an': 32,\n",
       " 'they': 33,\n",
       " 'who': 34,\n",
       " 'so': 35,\n",
       " 'from': 36,\n",
       " 'like': 37,\n",
       " 'her': 38,\n",
       " 'or': 39,\n",
       " 'just': 40,\n",
       " 'about': 41,\n",
       " \"it's\": 42,\n",
       " 'out': 43,\n",
       " 'if': 44,\n",
       " 'has': 45,\n",
       " 'some': 46,\n",
       " 'there': 47,\n",
       " 'what': 48,\n",
       " 'good': 49,\n",
       " 'more': 50,\n",
       " 'when': 51,\n",
       " 'very': 52,\n",
       " 'up': 53,\n",
       " 'no': 54,\n",
       " 'time': 55,\n",
       " 'she': 56,\n",
       " 'even': 57,\n",
       " 'my': 58,\n",
       " 'would': 59,\n",
       " 'which': 60,\n",
       " 'only': 61,\n",
       " 'story': 62,\n",
       " 'really': 63,\n",
       " 'see': 64,\n",
       " 'their': 65,\n",
       " 'had': 66,\n",
       " 'can': 67,\n",
       " 'were': 68,\n",
       " 'me': 69,\n",
       " 'well': 70,\n",
       " 'than': 71,\n",
       " 'we': 72,\n",
       " 'much': 73,\n",
       " 'been': 74,\n",
       " 'bad': 75,\n",
       " 'get': 76,\n",
       " 'will': 77,\n",
       " 'do': 78,\n",
       " 'also': 79,\n",
       " 'into': 80,\n",
       " 'people': 81,\n",
       " 'other': 82,\n",
       " 'first': 83,\n",
       " 'great': 84,\n",
       " 'because': 85,\n",
       " 'how': 86,\n",
       " 'him': 87,\n",
       " 'most': 88,\n",
       " \"don't\": 89,\n",
       " 'made': 90,\n",
       " 'its': 91,\n",
       " 'then': 92,\n",
       " 'way': 93,\n",
       " 'make': 94,\n",
       " 'them': 95,\n",
       " 'too': 96,\n",
       " 'could': 97,\n",
       " 'any': 98,\n",
       " 'movies': 99,\n",
       " 'after': 100,\n",
       " 'think': 101,\n",
       " 'characters': 102,\n",
       " 'watch': 103,\n",
       " 'two': 104,\n",
       " 'films': 105,\n",
       " 'character': 106,\n",
       " 'seen': 107,\n",
       " 'many': 108,\n",
       " 'being': 109,\n",
       " 'life': 110,\n",
       " 'plot': 111,\n",
       " 'never': 112,\n",
       " 'acting': 113,\n",
       " 'little': 114,\n",
       " 'best': 115,\n",
       " 'love': 116,\n",
       " 'over': 117,\n",
       " 'where': 118,\n",
       " 'did': 119,\n",
       " 'show': 120,\n",
       " 'know': 121,\n",
       " 'off': 122,\n",
       " 'ever': 123,\n",
       " 'does': 124,\n",
       " 'better': 125,\n",
       " 'your': 126,\n",
       " 'end': 127,\n",
       " 'still': 128,\n",
       " 'man': 129,\n",
       " 'here': 130,\n",
       " 'these': 131,\n",
       " 'say': 132,\n",
       " 'scene': 133,\n",
       " 'while': 134,\n",
       " 'why': 135,\n",
       " 'scenes': 136,\n",
       " 'go': 137,\n",
       " 'such': 138,\n",
       " 'something': 139,\n",
       " 'through': 140,\n",
       " 'should': 141,\n",
       " 'back': 142,\n",
       " \"i'm\": 143,\n",
       " 'real': 144,\n",
       " 'those': 145,\n",
       " 'watching': 146,\n",
       " 'now': 147,\n",
       " 'though': 148,\n",
       " \"doesn't\": 149,\n",
       " 'years': 150,\n",
       " 'thing': 151,\n",
       " 'old': 152,\n",
       " 'actors': 153,\n",
       " 'work': 154,\n",
       " '10': 155,\n",
       " 'before': 156,\n",
       " 'another': 157,\n",
       " \"didn't\": 158,\n",
       " 'new': 159,\n",
       " 'funny': 160,\n",
       " 'nothing': 161,\n",
       " 'actually': 162,\n",
       " 'makes': 163,\n",
       " 'director': 164,\n",
       " 'look': 165,\n",
       " 'find': 166,\n",
       " 'going': 167,\n",
       " 'few': 168,\n",
       " 'same': 169,\n",
       " 'part': 170,\n",
       " 'again': 171,\n",
       " 'every': 172,\n",
       " 'lot': 173,\n",
       " 'cast': 174,\n",
       " 'us': 175,\n",
       " 'quite': 176,\n",
       " 'down': 177,\n",
       " 'want': 178,\n",
       " 'world': 179,\n",
       " 'things': 180,\n",
       " 'pretty': 181,\n",
       " 'young': 182,\n",
       " 'seems': 183,\n",
       " 'around': 184,\n",
       " 'got': 185,\n",
       " 'horror': 186,\n",
       " 'however': 187,\n",
       " \"can't\": 188,\n",
       " 'fact': 189,\n",
       " 'take': 190,\n",
       " 'big': 191,\n",
       " 'enough': 192,\n",
       " 'long': 193,\n",
       " 'thought': 194,\n",
       " \"that's\": 195,\n",
       " 'both': 196,\n",
       " 'between': 197,\n",
       " 'series': 198,\n",
       " 'give': 199,\n",
       " 'may': 200,\n",
       " 'original': 201,\n",
       " 'action': 202,\n",
       " 'own': 203,\n",
       " \"i've\": 204,\n",
       " 'right': 205,\n",
       " 'without': 206,\n",
       " 'always': 207,\n",
       " 'times': 208,\n",
       " 'comedy': 209,\n",
       " 'point': 210,\n",
       " 'gets': 211,\n",
       " 'must': 212,\n",
       " 'come': 213,\n",
       " 'role': 214,\n",
       " \"isn't\": 215,\n",
       " 'saw': 216,\n",
       " 'almost': 217,\n",
       " 'interesting': 218,\n",
       " 'least': 219,\n",
       " 'family': 220,\n",
       " 'done': 221,\n",
       " \"there's\": 222,\n",
       " 'whole': 223,\n",
       " 'bit': 224,\n",
       " 'music': 225,\n",
       " 'script': 226,\n",
       " 'far': 227,\n",
       " 'making': 228,\n",
       " 'guy': 229,\n",
       " 'anything': 230,\n",
       " 'minutes': 231,\n",
       " 'feel': 232,\n",
       " 'last': 233,\n",
       " 'since': 234,\n",
       " 'might': 235,\n",
       " 'performance': 236,\n",
       " \"he's\": 237,\n",
       " '2': 238,\n",
       " 'probably': 239,\n",
       " 'kind': 240,\n",
       " 'am': 241,\n",
       " 'away': 242,\n",
       " 'yet': 243,\n",
       " 'rather': 244,\n",
       " 'tv': 245,\n",
       " 'worst': 246,\n",
       " 'girl': 247,\n",
       " 'day': 248,\n",
       " 'sure': 249,\n",
       " 'fun': 250,\n",
       " 'hard': 251,\n",
       " 'woman': 252,\n",
       " 'played': 253,\n",
       " 'each': 254,\n",
       " 'found': 255,\n",
       " 'anyone': 256,\n",
       " 'having': 257,\n",
       " 'especially': 258,\n",
       " 'although': 259,\n",
       " 'our': 260,\n",
       " 'course': 261,\n",
       " 'believe': 262,\n",
       " 'comes': 263,\n",
       " 'looking': 264,\n",
       " 'screen': 265,\n",
       " 'trying': 266,\n",
       " 'set': 267,\n",
       " 'goes': 268,\n",
       " 'looks': 269,\n",
       " 'place': 270,\n",
       " 'book': 271,\n",
       " 'different': 272,\n",
       " 'put': 273,\n",
       " 'ending': 274,\n",
       " 'money': 275,\n",
       " 'maybe': 276,\n",
       " 'once': 277,\n",
       " 'sense': 278,\n",
       " 'reason': 279,\n",
       " 'true': 280,\n",
       " 'actor': 281,\n",
       " 'everything': 282,\n",
       " \"wasn't\": 283,\n",
       " 'shows': 284,\n",
       " 'dvd': 285,\n",
       " 'three': 286,\n",
       " 'worth': 287,\n",
       " 'year': 288,\n",
       " 'job': 289,\n",
       " 'main': 290,\n",
       " 'someone': 291,\n",
       " 'together': 292,\n",
       " 'watched': 293,\n",
       " 'play': 294,\n",
       " 'plays': 295,\n",
       " 'american': 296,\n",
       " '1': 297,\n",
       " 'said': 298,\n",
       " 'effects': 299,\n",
       " 'later': 300,\n",
       " 'takes': 301,\n",
       " 'instead': 302,\n",
       " 'seem': 303,\n",
       " 'beautiful': 304,\n",
       " 'john': 305,\n",
       " 'himself': 306,\n",
       " 'version': 307,\n",
       " 'audience': 308,\n",
       " 'high': 309,\n",
       " 'house': 310,\n",
       " 'night': 311,\n",
       " 'during': 312,\n",
       " 'everyone': 313,\n",
       " 'left': 314,\n",
       " 'special': 315,\n",
       " 'seeing': 316,\n",
       " 'half': 317,\n",
       " 'excellent': 318,\n",
       " 'wife': 319,\n",
       " 'star': 320,\n",
       " 'shot': 321,\n",
       " 'war': 322,\n",
       " 'idea': 323,\n",
       " 'nice': 324,\n",
       " 'black': 325,\n",
       " 'less': 326,\n",
       " 'mind': 327,\n",
       " 'simply': 328,\n",
       " 'read': 329,\n",
       " 'second': 330,\n",
       " 'else': 331,\n",
       " \"you're\": 332,\n",
       " 'father': 333,\n",
       " 'fan': 334,\n",
       " 'help': 335,\n",
       " 'poor': 336,\n",
       " 'completely': 337,\n",
       " 'death': 338,\n",
       " '3': 339,\n",
       " 'used': 340,\n",
       " 'home': 341,\n",
       " 'either': 342,\n",
       " 'short': 343,\n",
       " 'line': 344,\n",
       " 'given': 345,\n",
       " 'men': 346,\n",
       " 'top': 347,\n",
       " 'dead': 348,\n",
       " 'budget': 349,\n",
       " 'try': 350,\n",
       " 'performances': 351,\n",
       " 'wrong': 352,\n",
       " 'classic': 353,\n",
       " 'enjoy': 354,\n",
       " 'boring': 355,\n",
       " 'need': 356,\n",
       " 'rest': 357,\n",
       " 'use': 358,\n",
       " 'kids': 359,\n",
       " 'hollywood': 360,\n",
       " 'low': 361,\n",
       " 'production': 362,\n",
       " 'until': 363,\n",
       " 'along': 364,\n",
       " 'friends': 365,\n",
       " 'full': 366,\n",
       " 'camera': 367,\n",
       " 'truly': 368,\n",
       " 'women': 369,\n",
       " 'awful': 370,\n",
       " 'video': 371,\n",
       " 'next': 372,\n",
       " 'tell': 373,\n",
       " 'remember': 374,\n",
       " 'stupid': 375,\n",
       " 'couple': 376,\n",
       " 'start': 377,\n",
       " 'perhaps': 378,\n",
       " 'stars': 379,\n",
       " 'sex': 380,\n",
       " 'mean': 381,\n",
       " 'came': 382,\n",
       " 'recommend': 383,\n",
       " 'let': 384,\n",
       " 'moments': 385,\n",
       " 'wonderful': 386,\n",
       " 'episode': 387,\n",
       " 'understand': 388,\n",
       " 'small': 389,\n",
       " 'face': 390,\n",
       " 'terrible': 391,\n",
       " 'playing': 392,\n",
       " 'school': 393,\n",
       " 'getting': 394,\n",
       " 'written': 395,\n",
       " 'often': 396,\n",
       " 'doing': 397,\n",
       " 'keep': 398,\n",
       " 'early': 399,\n",
       " 'name': 400,\n",
       " 'perfect': 401,\n",
       " 'style': 402,\n",
       " 'human': 403,\n",
       " 'definitely': 404,\n",
       " 'others': 405,\n",
       " 'gives': 406,\n",
       " 'itself': 407,\n",
       " 'lines': 408,\n",
       " 'live': 409,\n",
       " 'become': 410,\n",
       " 'dialogue': 411,\n",
       " 'person': 412,\n",
       " 'lost': 413,\n",
       " 'finally': 414,\n",
       " 'piece': 415,\n",
       " 'head': 416,\n",
       " 'felt': 417,\n",
       " 'case': 418,\n",
       " 'yes': 419,\n",
       " 'liked': 420,\n",
       " 'supposed': 421,\n",
       " 'title': 422,\n",
       " \"couldn't\": 423,\n",
       " 'absolutely': 424,\n",
       " 'white': 425,\n",
       " 'against': 426,\n",
       " 'boy': 427,\n",
       " 'picture': 428,\n",
       " 'sort': 429,\n",
       " 'worse': 430,\n",
       " 'certainly': 431,\n",
       " 'went': 432,\n",
       " 'entire': 433,\n",
       " 'waste': 434,\n",
       " 'cinema': 435,\n",
       " 'problem': 436,\n",
       " 'hope': 437,\n",
       " \"she's\": 438,\n",
       " 'entertaining': 439,\n",
       " 'mr': 440,\n",
       " 'overall': 441,\n",
       " 'evil': 442,\n",
       " 'called': 443,\n",
       " 'loved': 444,\n",
       " 'based': 445,\n",
       " 'oh': 446,\n",
       " 'several': 447,\n",
       " 'fans': 448,\n",
       " 'mother': 449,\n",
       " 'drama': 450,\n",
       " 'beginning': 451,\n",
       " 'killer': 452,\n",
       " 'lives': 453,\n",
       " '5': 454,\n",
       " 'direction': 455,\n",
       " 'care': 456,\n",
       " 'already': 457,\n",
       " 'becomes': 458,\n",
       " 'laugh': 459,\n",
       " 'example': 460,\n",
       " 'friend': 461,\n",
       " 'dark': 462,\n",
       " 'despite': 463,\n",
       " 'under': 464,\n",
       " 'seemed': 465,\n",
       " 'throughout': 466,\n",
       " '4': 467,\n",
       " 'turn': 468,\n",
       " 'unfortunately': 469,\n",
       " 'wanted': 470,\n",
       " \"i'd\": 471,\n",
       " '\\x96': 472,\n",
       " 'children': 473,\n",
       " 'final': 474,\n",
       " 'fine': 475,\n",
       " 'history': 476,\n",
       " 'amazing': 477,\n",
       " 'sound': 478,\n",
       " 'guess': 479,\n",
       " 'heart': 480,\n",
       " 'totally': 481,\n",
       " 'humor': 482,\n",
       " 'lead': 483,\n",
       " 'writing': 484,\n",
       " 'michael': 485,\n",
       " 'quality': 486,\n",
       " \"you'll\": 487,\n",
       " 'close': 488,\n",
       " 'son': 489,\n",
       " 'wants': 490,\n",
       " 'guys': 491,\n",
       " 'works': 492,\n",
       " 'behind': 493,\n",
       " 'tries': 494,\n",
       " 'art': 495,\n",
       " 'side': 496,\n",
       " 'game': 497,\n",
       " 'past': 498,\n",
       " 'able': 499,\n",
       " 'b': 500,\n",
       " 'days': 501,\n",
       " 'turns': 502,\n",
       " \"they're\": 503,\n",
       " 'child': 504,\n",
       " 'hand': 505,\n",
       " 'flick': 506,\n",
       " 'enjoyed': 507,\n",
       " 'act': 508,\n",
       " 'genre': 509,\n",
       " 'town': 510,\n",
       " 'favorite': 511,\n",
       " 'soon': 512,\n",
       " 'kill': 513,\n",
       " 'starts': 514,\n",
       " 'sometimes': 515,\n",
       " 'car': 516,\n",
       " 'gave': 517,\n",
       " 'run': 518,\n",
       " 'late': 519,\n",
       " 'eyes': 520,\n",
       " 'etc': 521,\n",
       " 'actress': 522,\n",
       " 'directed': 523,\n",
       " 'horrible': 524,\n",
       " \"won't\": 525,\n",
       " 'viewer': 526,\n",
       " 'brilliant': 527,\n",
       " 'parts': 528,\n",
       " 'self': 529,\n",
       " 'themselves': 530,\n",
       " 'hour': 531,\n",
       " 'expect': 532,\n",
       " 'thinking': 533,\n",
       " 'stories': 534,\n",
       " 'stuff': 535,\n",
       " 'girls': 536,\n",
       " 'obviously': 537,\n",
       " 'blood': 538,\n",
       " 'decent': 539,\n",
       " 'city': 540,\n",
       " 'voice': 541,\n",
       " 'highly': 542,\n",
       " 'myself': 543,\n",
       " 'feeling': 544,\n",
       " 'fight': 545,\n",
       " 'except': 546,\n",
       " 'slow': 547,\n",
       " 'matter': 548,\n",
       " 'type': 549,\n",
       " 'anyway': 550,\n",
       " 'kid': 551,\n",
       " 'roles': 552,\n",
       " 'heard': 553,\n",
       " 'killed': 554,\n",
       " 'age': 555,\n",
       " 'says': 556,\n",
       " 'god': 557,\n",
       " 'moment': 558,\n",
       " 'took': 559,\n",
       " 'leave': 560,\n",
       " 'writer': 561,\n",
       " 'strong': 562,\n",
       " 'cannot': 563,\n",
       " 'violence': 564,\n",
       " 'police': 565,\n",
       " 'hit': 566,\n",
       " 'stop': 567,\n",
       " 'happens': 568,\n",
       " 'particularly': 569,\n",
       " 'known': 570,\n",
       " 'happened': 571,\n",
       " 'involved': 572,\n",
       " 'extremely': 573,\n",
       " 'obvious': 574,\n",
       " 'daughter': 575,\n",
       " 'chance': 576,\n",
       " 'told': 577,\n",
       " 'living': 578,\n",
       " 'coming': 579,\n",
       " 'lack': 580,\n",
       " 'experience': 581,\n",
       " 'alone': 582,\n",
       " \"wouldn't\": 583,\n",
       " 'including': 584,\n",
       " 'murder': 585,\n",
       " 'attempt': 586,\n",
       " 's': 587,\n",
       " 'please': 588,\n",
       " 'james': 589,\n",
       " 'happen': 590,\n",
       " 'wonder': 591,\n",
       " 'crap': 592,\n",
       " 'brother': 593,\n",
       " 'ago': 594,\n",
       " \"film's\": 595,\n",
       " 'gore': 596,\n",
       " 'complete': 597,\n",
       " 'none': 598,\n",
       " 'interest': 599,\n",
       " 'score': 600,\n",
       " 'group': 601,\n",
       " 'cut': 602,\n",
       " 'simple': 603,\n",
       " 'save': 604,\n",
       " 'looked': 605,\n",
       " 'hell': 606,\n",
       " 'ok': 607,\n",
       " 'number': 608,\n",
       " 'career': 609,\n",
       " 'song': 610,\n",
       " 'possible': 611,\n",
       " 'seriously': 612,\n",
       " 'annoying': 613,\n",
       " 'exactly': 614,\n",
       " 'shown': 615,\n",
       " 'sad': 616,\n",
       " 'running': 617,\n",
       " 'musical': 618,\n",
       " 'serious': 619,\n",
       " 'yourself': 620,\n",
       " 'taken': 621,\n",
       " 'whose': 622,\n",
       " 'released': 623,\n",
       " 'cinematography': 624,\n",
       " 'david': 625,\n",
       " 'scary': 626,\n",
       " 'ends': 627,\n",
       " 'usually': 628,\n",
       " 'hero': 629,\n",
       " 'english': 630,\n",
       " 'hours': 631,\n",
       " 'reality': 632,\n",
       " 'opening': 633,\n",
       " \"i'll\": 634,\n",
       " 'light': 635,\n",
       " 'across': 636,\n",
       " 'jokes': 637,\n",
       " 'today': 638,\n",
       " 'hilarious': 639,\n",
       " 'somewhat': 640,\n",
       " 'usual': 641,\n",
       " 'started': 642,\n",
       " 'body': 643,\n",
       " 'ridiculous': 644,\n",
       " 'cool': 645,\n",
       " 'view': 646,\n",
       " 'relationship': 647,\n",
       " 'level': 648,\n",
       " 'change': 649,\n",
       " 'opinion': 650,\n",
       " 'happy': 651,\n",
       " 'middle': 652,\n",
       " 'taking': 653,\n",
       " 'wish': 654,\n",
       " 'husband': 655,\n",
       " 'finds': 656,\n",
       " 'saying': 657,\n",
       " 'order': 658,\n",
       " 'shots': 659,\n",
       " 'talking': 660,\n",
       " 'ones': 661,\n",
       " 'documentary': 662,\n",
       " 'huge': 663,\n",
       " 'novel': 664,\n",
       " 'female': 665,\n",
       " 'mostly': 666,\n",
       " 'power': 667,\n",
       " 'robert': 668,\n",
       " 'episodes': 669,\n",
       " 'room': 670,\n",
       " 'important': 671,\n",
       " 'rating': 672,\n",
       " 'talent': 673,\n",
       " 'five': 674,\n",
       " 'major': 675,\n",
       " 'turned': 676,\n",
       " 'strange': 677,\n",
       " 'word': 678,\n",
       " 'modern': 679,\n",
       " 'call': 680,\n",
       " 'apparently': 681,\n",
       " 'disappointed': 682,\n",
       " 'single': 683,\n",
       " 'events': 684,\n",
       " 'four': 685,\n",
       " 'due': 686,\n",
       " 'songs': 687,\n",
       " 'basically': 688,\n",
       " 'attention': 689,\n",
       " '7': 690,\n",
       " 'knows': 691,\n",
       " 'clearly': 692,\n",
       " 'knew': 693,\n",
       " 'supporting': 694,\n",
       " 'comic': 695,\n",
       " 'non': 696,\n",
       " 'television': 697,\n",
       " 'british': 698,\n",
       " 'fast': 699,\n",
       " 'earth': 700,\n",
       " 'country': 701,\n",
       " 'cheap': 702,\n",
       " 'class': 703,\n",
       " 'future': 704,\n",
       " 'thriller': 705,\n",
       " 'silly': 706,\n",
       " '8': 707,\n",
       " 'king': 708,\n",
       " 'problems': 709,\n",
       " \"aren't\": 710,\n",
       " 'easily': 711,\n",
       " 'words': 712,\n",
       " 'tells': 713,\n",
       " 'miss': 714,\n",
       " 'jack': 715,\n",
       " 'local': 716,\n",
       " 'sequence': 717,\n",
       " 'bring': 718,\n",
       " 'entertainment': 719,\n",
       " 'paul': 720,\n",
       " 'beyond': 721,\n",
       " 'upon': 722,\n",
       " 'whether': 723,\n",
       " 'moving': 724,\n",
       " 'predictable': 725,\n",
       " 'sets': 726,\n",
       " 'romantic': 727,\n",
       " 'straight': 728,\n",
       " 'similar': 729,\n",
       " 'review': 730,\n",
       " 'falls': 731,\n",
       " 'oscar': 732,\n",
       " 'mystery': 733,\n",
       " 'enjoyable': 734,\n",
       " 'appears': 735,\n",
       " 'rock': 736,\n",
       " 'needs': 737,\n",
       " 'talk': 738,\n",
       " 'george': 739,\n",
       " 'giving': 740,\n",
       " 'eye': 741,\n",
       " 'within': 742,\n",
       " 'richard': 743,\n",
       " 'ten': 744,\n",
       " 'animation': 745,\n",
       " 'message': 746,\n",
       " 'near': 747,\n",
       " 'theater': 748,\n",
       " 'above': 749,\n",
       " 'dull': 750,\n",
       " 'nearly': 751,\n",
       " 'sequel': 752,\n",
       " 'points': 753,\n",
       " 'theme': 754,\n",
       " 'stand': 755,\n",
       " \"'\": 756,\n",
       " 'mention': 757,\n",
       " 'lady': 758,\n",
       " 'add': 759,\n",
       " 'bunch': 760,\n",
       " 'herself': 761,\n",
       " 'feels': 762,\n",
       " 'release': 763,\n",
       " 'red': 764,\n",
       " 'team': 765,\n",
       " 'storyline': 766,\n",
       " 'surprised': 767,\n",
       " 'ways': 768,\n",
       " 'named': 769,\n",
       " 'using': 770,\n",
       " \"haven't\": 771,\n",
       " 'lots': 772,\n",
       " 'easy': 773,\n",
       " 'fantastic': 774,\n",
       " 'begins': 775,\n",
       " 'actual': 776,\n",
       " 'working': 777,\n",
       " 'effort': 778,\n",
       " 'york': 779,\n",
       " 'french': 780,\n",
       " 'hate': 781,\n",
       " 'die': 782,\n",
       " 'minute': 783,\n",
       " 'tale': 784,\n",
       " 'clear': 785,\n",
       " 'stay': 786,\n",
       " '9': 787,\n",
       " 'elements': 788,\n",
       " 'feature': 789,\n",
       " 'among': 790,\n",
       " 'follow': 791,\n",
       " 'comments': 792,\n",
       " 're': 793,\n",
       " 'avoid': 794,\n",
       " 'viewers': 795,\n",
       " 'sister': 796,\n",
       " 'typical': 797,\n",
       " 'showing': 798,\n",
       " 'editing': 799,\n",
       " 'tried': 800,\n",
       " \"what's\": 801,\n",
       " 'famous': 802,\n",
       " 'sorry': 803,\n",
       " 'dialog': 804,\n",
       " 'fall': 805,\n",
       " 'check': 806,\n",
       " 'period': 807,\n",
       " 'form': 808,\n",
       " 'season': 809,\n",
       " 'certain': 810,\n",
       " 'filmed': 811,\n",
       " 'weak': 812,\n",
       " 'soundtrack': 813,\n",
       " 'means': 814,\n",
       " 'material': 815,\n",
       " 'buy': 816,\n",
       " 'realistic': 817,\n",
       " 'somehow': 818,\n",
       " 'crime': 819,\n",
       " 'figure': 820,\n",
       " 'gone': 821,\n",
       " 'doubt': 822,\n",
       " 'peter': 823,\n",
       " 'tom': 824,\n",
       " 'viewing': 825,\n",
       " 'kept': 826,\n",
       " 't': 827,\n",
       " 'general': 828,\n",
       " 'leads': 829,\n",
       " 'greatest': 830,\n",
       " 'space': 831,\n",
       " 'lame': 832,\n",
       " 'suspense': 833,\n",
       " 'dance': 834,\n",
       " 'imagine': 835,\n",
       " 'brought': 836,\n",
       " 'third': 837,\n",
       " 'atmosphere': 838,\n",
       " 'hear': 839,\n",
       " 'particular': 840,\n",
       " 'whatever': 841,\n",
       " 'sequences': 842,\n",
       " 'parents': 843,\n",
       " 'move': 844,\n",
       " 'lee': 845,\n",
       " 'indeed': 846,\n",
       " 'rent': 847,\n",
       " 'eventually': 848,\n",
       " 'learn': 849,\n",
       " 'de': 850,\n",
       " 'note': 851,\n",
       " 'deal': 852,\n",
       " 'average': 853,\n",
       " 'forget': 854,\n",
       " 'reviews': 855,\n",
       " 'wait': 856,\n",
       " 'japanese': 857,\n",
       " 'sexual': 858,\n",
       " 'poorly': 859,\n",
       " 'premise': 860,\n",
       " 'okay': 861,\n",
       " 'zombie': 862,\n",
       " 'surprise': 863,\n",
       " 'believable': 864,\n",
       " 'stage': 865,\n",
       " 'sit': 866,\n",
       " 'possibly': 867,\n",
       " \"who's\": 868,\n",
       " 'decided': 869,\n",
       " 'expected': 870,\n",
       " \"you've\": 871,\n",
       " 'subject': 872,\n",
       " 'nature': 873,\n",
       " 'became': 874,\n",
       " 'difficult': 875,\n",
       " 'free': 876,\n",
       " 'screenplay': 877,\n",
       " 'killing': 878,\n",
       " 'truth': 879,\n",
       " 'romance': 880,\n",
       " 'dr': 881,\n",
       " 'nor': 882,\n",
       " 'reading': 883,\n",
       " 'needed': 884,\n",
       " 'question': 885,\n",
       " 'leaves': 886,\n",
       " 'street': 887,\n",
       " '20': 888,\n",
       " 'meets': 889,\n",
       " 'hot': 890,\n",
       " 'begin': 891,\n",
       " 'unless': 892,\n",
       " 'baby': 893,\n",
       " 'otherwise': 894,\n",
       " 'credits': 895,\n",
       " 'imdb': 896,\n",
       " 'superb': 897,\n",
       " 'write': 898,\n",
       " 'shame': 899,\n",
       " \"let's\": 900,\n",
       " 'dramatic': 901,\n",
       " 'situation': 902,\n",
       " 'memorable': 903,\n",
       " 'earlier': 904,\n",
       " 'directors': 905,\n",
       " 'badly': 906,\n",
       " 'dog': 907,\n",
       " 'meet': 908,\n",
       " 'disney': 909,\n",
       " 'open': 910,\n",
       " 'weird': 911,\n",
       " 'male': 912,\n",
       " 'joe': 913,\n",
       " 'acted': 914,\n",
       " 'forced': 915,\n",
       " 'sci': 916,\n",
       " 'laughs': 917,\n",
       " 'emotional': 918,\n",
       " 'older': 919,\n",
       " 'realize': 920,\n",
       " 'fi': 921,\n",
       " 'society': 922,\n",
       " 'dream': 923,\n",
       " 'writers': 924,\n",
       " 'interested': 925,\n",
       " 'forward': 926,\n",
       " 'comment': 927,\n",
       " 'footage': 928,\n",
       " 'crazy': 929,\n",
       " 'deep': 930,\n",
       " 'whom': 931,\n",
       " 'beauty': 932,\n",
       " 'plus': 933,\n",
       " 'america': 934,\n",
       " 'sounds': 935,\n",
       " 'fantasy': 936,\n",
       " 'directing': 937,\n",
       " 'keeps': 938,\n",
       " 'ask': 939,\n",
       " 'development': 940,\n",
       " 'features': 941,\n",
       " 'quickly': 942,\n",
       " 'air': 943,\n",
       " 'creepy': 944,\n",
       " 'mess': 945,\n",
       " 'towards': 946,\n",
       " 'perfectly': 947,\n",
       " 'mark': 948,\n",
       " 'worked': 949,\n",
       " 'box': 950,\n",
       " 'cheesy': 951,\n",
       " 'unique': 952,\n",
       " 'hands': 953,\n",
       " 'setting': 954,\n",
       " 'plenty': 955,\n",
       " 'result': 956,\n",
       " 'previous': 957,\n",
       " 'brings': 958,\n",
       " 'effect': 959,\n",
       " 'total': 960,\n",
       " 'e': 961,\n",
       " 'personal': 962,\n",
       " 'incredibly': 963,\n",
       " 'rate': 964,\n",
       " 'monster': 965,\n",
       " 'fire': 966,\n",
       " 'business': 967,\n",
       " 'apart': 968,\n",
       " 'leading': 969,\n",
       " 'casting': 970,\n",
       " 'admit': 971,\n",
       " 'appear': 972,\n",
       " 'joke': 973,\n",
       " 'background': 974,\n",
       " 'powerful': 975,\n",
       " 'meant': 976,\n",
       " 'girlfriend': 977,\n",
       " 'telling': 978,\n",
       " 'hardly': 979,\n",
       " 'present': 980,\n",
       " 'christmas': 981,\n",
       " 'battle': 982,\n",
       " 'potential': 983,\n",
       " 'create': 984,\n",
       " 'break': 985,\n",
       " 'bill': 986,\n",
       " 'pay': 987,\n",
       " 'masterpiece': 988,\n",
       " 'return': 989,\n",
       " 'gay': 990,\n",
       " 'political': 991,\n",
       " 'dumb': 992,\n",
       " 'fighting': 993,\n",
       " 'fails': 994,\n",
       " 'various': 995,\n",
       " 'portrayed': 996,\n",
       " 'era': 997,\n",
       " 'secret': 998,\n",
       " 'cop': 999,\n",
       " 'co': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:40:10.656818Z",
     "start_time": "2018-04-25T15:40:10.328090Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pad_sequences(sequences, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:40:10.664234Z",
     "start_time": "2018-04-25T15:40:10.658577Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.asarray(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:40:10.759527Z",
     "start_time": "2018-04-25T15:40:10.665587Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:40:10.856252Z",
     "start_time": "2018-04-25T15:40:10.762507Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: training_samples + validation_samples]\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:45:13.986746Z",
     "start_time": "2018-04-25T15:45:13.983942Z"
    }
   },
   "outputs": [],
   "source": [
    "glove_dir = './data/glove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:45:32.599675Z",
     "start_time": "2018-04-25T15:45:15.028301Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's build an embedding matrix that we will be able to load into an embedding layer. It must be a matrix of shape (max_words, embedding_dim). Note that the index 0 is not supposed to stand for any word or token -- it's a placeholder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:45:32.688277Z",
     "start_time": "2018-04-25T15:45:32.601644Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:45:35.284926Z",
     "start_time": "2018-04-25T15:45:35.281976Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:45:36.146378Z",
     "start_time": "2018-04-25T15:45:36.059061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 100, 100)          1000000   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                320032    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,320,065\n",
      "Trainable params: 1,320,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_words, embedding_dim, input_length = maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the GloVe embeddings in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:45:38.853467Z",
     "start_time": "2018-04-25T15:45:38.782910Z"
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:45:45.546004Z",
     "start_time": "2018-04-25T15:45:40.036611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 1s - loss: 1.4161 - acc: 0.5200 - val_loss: 0.7040 - val_acc: 0.5121\n",
      "Epoch 2/10\n",
      " - 0s - loss: 0.6880 - acc: 0.6600 - val_loss: 0.7343 - val_acc: 0.5146\n",
      "Epoch 3/10\n",
      " - 0s - loss: 0.5421 - acc: 0.7350 - val_loss: 0.8689 - val_acc: 0.4946\n",
      "Epoch 4/10\n",
      " - 0s - loss: 0.3586 - acc: 0.8500 - val_loss: 0.8633 - val_acc: 0.5041\n",
      "Epoch 5/10\n",
      " - 0s - loss: 0.2856 - acc: 0.9000 - val_loss: 0.6956 - val_acc: 0.5648\n",
      "Epoch 6/10\n",
      " - 0s - loss: 0.1613 - acc: 0.9850 - val_loss: 0.7378 - val_acc: 0.5529\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.1113 - acc: 0.9900 - val_loss: 0.7838 - val_acc: 0.5451\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.1684 - acc: 0.9300 - val_loss: 0.7475 - val_acc: 0.5715\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0512 - acc: 1.0000 - val_loss: 0.8037 - val_acc: 0.5654\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0306 - acc: 1.0000 - val_loss: 0.8054 - val_acc: 0.5690\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T15:45:45.839540Z",
     "start_time": "2018-04-25T15:45:45.548116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
