{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Sequence to sequence learning is about training models to convert sequences from one domain to sequences in another domain. This can be used for machine translation or for free-form question answering or in general, it is applicable any time you need to generate text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to handle this task, either using RNNs or using 1D convnets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Trivial case - Input and output sequences have same length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "When both input sequences and output sequences have the same length, you can implement such models simply with a keras LSTM or GRU layer. (or a stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Teaching a RNN to learn to add numbers, encoded as character strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-04T10:46:01.192383Z",
     "start_time": "2017-10-04T10:46:01.184235Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Input \"535+51\"\n",
    "Output \"596\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:43.251827Z",
     "start_time": "2017-10-15T14:48:26.708063Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:43.271817Z",
     "start_time": "2017-10-15T14:48:43.254169Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class CharacterTable(object):\n",
    "    \"\"\"Given a set of characters:\n",
    "    + Encode them to a one hot integer representation\n",
    "    + Decode the one hot integer representation to their character output\n",
    "    + Decode a vector of probabilities to their character output\n",
    "    \"\"\"\n",
    "    def __init__(self, chars):\n",
    "        \"\"\"Initialize character table.\n",
    "\n",
    "        # Arguments\n",
    "            chars: Characters that can appear in the input.\n",
    "        \"\"\"\n",
    "        self.chars = sorted(set(chars))\n",
    "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
    "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
    "\n",
    "    def encode(self, C, num_rows):\n",
    "        \"\"\"One hot encode given string C.\n",
    "\n",
    "        # Arguments\n",
    "            num_rows: Number of rows in the returned one hot encoding. This is\n",
    "                used to keep the # of rows for each data the same.\n",
    "        \"\"\"\n",
    "        x = np.zeros((num_rows, len(self.chars)))\n",
    "        for i, c in enumerate(C):\n",
    "            x[i, self.char_indices[c]] = 1\n",
    "        return x\n",
    "\n",
    "    def decode(self, x, calc_argmax=True):\n",
    "        if calc_argmax:\n",
    "            x = x.argmax(axis=-1)\n",
    "        return ''.join(self.indices_char[x] for x in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:43.429953Z",
     "start_time": "2017-10-15T14:48:43.273529Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class colors:\n",
    "    ok = '\\033[92m'\n",
    "    fail = '\\033[91m'\n",
    "    close = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:43.509256Z",
     "start_time": "2017-10-15T14:48:43.433802Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Parameters for the model and dataset.\n",
    "TRAINING_SIZE = 50000\n",
    "DIGITS = 3\n",
    "INVERT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:43.626625Z",
     "start_time": "2017-10-15T14:48:43.512860Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
    "# int is DIGITS.\n",
    "MAXLEN = DIGITS + 1 + DIGITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:43.743529Z",
     "start_time": "2017-10-15T14:48:43.632157Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# All the numbers, plus sign and space for padding.\n",
    "chars = '0123456789+ '\n",
    "ctable = CharacterTable(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:53.817025Z",
     "start_time": "2017-10-15T14:48:43.747611Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data...\n",
      "Total addition questions: 50000\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "expected = []\n",
    "seen = set()\n",
    "print('Generating data...')\n",
    "while len(questions) < TRAINING_SIZE:\n",
    "    f = lambda: int(''.join(np.random.choice(list('0123456789'))\n",
    "                    for i in range(np.random.randint(1, DIGITS + 1))))\n",
    "    a, b = f(), f()\n",
    "    # Skip any addition questions we've already seen\n",
    "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
    "    key = tuple(sorted((a, b)))\n",
    "    if key in seen:\n",
    "        continue\n",
    "    seen.add(key)\n",
    "    # Pad the data with spaces such that it is always MAXLEN.\n",
    "    q = '{}+{}'.format(a, b)\n",
    "    query = q + ' ' * (MAXLEN - len(q))\n",
    "    ans = str(a + b)\n",
    "    # Answers can be of maximum size DIGITS + 1.\n",
    "    ans += ' ' * (DIGITS + 1 - len(ans))\n",
    "    if INVERT:\n",
    "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
    "        # space used for padding.)\n",
    "        query = query[::-1]\n",
    "    questions.append(query)\n",
    "    expected.append(ans)\n",
    "print('Total addition questions:', len(questions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:54.414312Z",
     "start_time": "2017-10-15T14:48:53.818539Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(questions):\n",
    "    x[i] = ctable.encode(sentence, MAXLEN)\n",
    "for i, sentence in enumerate(expected):\n",
    "    y[i] = ctable.encode(sentence, DIGITS + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:54.434078Z",
     "start_time": "2017-10-15T14:48:54.416541Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
    "# digits.\n",
    "indices = np.arange(len(y))\n",
    "np.random.shuffle(indices)\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:54.527885Z",
     "start_time": "2017-10-15T14:48:54.436513Z"
    },
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Explicitly set apart 10% for validation data that we never train over.\n",
    "split_at = len(x) - len(x) // 10\n",
    "(x_train, x_val) = x[:split_at], x[split_at:]\n",
    "(y_train, y_val) = y[:split_at], y[split_at:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:54.630603Z",
     "start_time": "2017-10-15T14:48:54.530764Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "(45000, 7, 12)\n",
      "(45000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Training Data:')\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:54.763680Z",
     "start_time": "2017-10-15T14:48:54.633703Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Data:\n",
      "(5000, 7, 12)\n",
      "(5000, 4, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Validation Data:')\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:54.877887Z",
     "start_time": "2017-10-15T14:48:54.767684Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:55.480434Z",
     "start_time": "2017-10-15T14:48:54.881917Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Encode the input sequence using LSTM\n",
    "model.add(LSTM(128, input_shape = (MAXLEN, len(chars))))\n",
    "# As the decoder RNN's input,\n",
    "# repeatedly provide with the last hidden state of RNN for each time step\n",
    "# DIGITS+1 as that's the maximum length of the output, e.g. max output is 999+999 = 1998\n",
    "model.add(layers.RepeatVector(DIGITS + 1))\n",
    "# By setting return_sequences to True, return not only the last output but\n",
    "# all the outputs so far in the form of (num_samples, timesteps, output_dim).\n",
    "model.add(LSTM(128, return_sequences = True))\n",
    "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
    "# of the output sequence, decide which character should be chosen.\n",
    "model.add(layers.TimeDistributed(layers.Dense(len(chars))))\n",
    "model.add(layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:55.518763Z",
     "start_time": "2017-10-15T14:48:55.482629Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:55.602086Z",
     "start_time": "2017-10-15T14:48:55.522870Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               72192     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 4, 128)            131584    \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4, 12)             1548      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4, 12)             0         \n",
      "=================================================================\n",
      "Total params: 205,324\n",
      "Trainable params: 205,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:48:55.899472Z",
     "start_time": "2017-10-15T14:48:55.604786Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='model.png' target='_blank'>model.png</a><br>"
      ],
      "text/plain": [
       "/home/sainath/code/py-snippets/nlp/model.png"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)  \n",
    "from IPython.display import FileLink\n",
    "FileLink('model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:57:47.785929Z",
     "start_time": "2017-10-15T14:48:55.901859Z"
    },
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "21s - loss: 1.8823 - acc: 0.3213 - val_loss: 1.8066 - val_acc: 0.3407\n",
      "Epoch 2/25\n",
      "21s - loss: 1.7342 - acc: 0.3589 - val_loss: 1.6608 - val_acc: 0.3816\n",
      "Epoch 3/25\n",
      "21s - loss: 1.5830 - acc: 0.4108 - val_loss: 1.5116 - val_acc: 0.4394\n",
      "Epoch 4/25\n",
      "21s - loss: 1.4168 - acc: 0.4695 - val_loss: 1.3361 - val_acc: 0.5123\n",
      "Epoch 5/25\n",
      "21s - loss: 1.2709 - acc: 0.5310 - val_loss: 1.2195 - val_acc: 0.5540\n",
      "Epoch 6/25\n",
      "21s - loss: 1.1710 - acc: 0.5687 - val_loss: 1.1314 - val_acc: 0.5848\n",
      "Epoch 7/25\n",
      "21s - loss: 1.0860 - acc: 0.6013 - val_loss: 1.0471 - val_acc: 0.6206\n",
      "Epoch 8/25\n",
      "21s - loss: 0.9999 - acc: 0.6351 - val_loss: 0.9636 - val_acc: 0.6505\n",
      "Epoch 9/25\n",
      "21s - loss: 0.9059 - acc: 0.6735 - val_loss: 0.8693 - val_acc: 0.6865\n",
      "Epoch 10/25\n",
      "21s - loss: 0.8309 - acc: 0.7041 - val_loss: 0.8064 - val_acc: 0.7115\n",
      "Epoch 11/25\n",
      "21s - loss: 0.7553 - acc: 0.7354 - val_loss: 0.7377 - val_acc: 0.7346\n",
      "Epoch 12/25\n",
      "21s - loss: 0.6618 - acc: 0.7709 - val_loss: 0.6145 - val_acc: 0.7811\n",
      "Epoch 13/25\n",
      "21s - loss: 0.5081 - acc: 0.8307 - val_loss: 0.4379 - val_acc: 0.8553\n",
      "Epoch 14/25\n",
      "21s - loss: 0.3607 - acc: 0.8950 - val_loss: 0.3245 - val_acc: 0.9067\n",
      "Epoch 15/25\n",
      "21s - loss: 0.2654 - acc: 0.9350 - val_loss: 0.2341 - val_acc: 0.9476\n",
      "Epoch 16/25\n",
      "21s - loss: 0.2030 - acc: 0.9552 - val_loss: 0.1749 - val_acc: 0.9660\n",
      "Epoch 17/25\n",
      "21s - loss: 0.1535 - acc: 0.9696 - val_loss: 0.1367 - val_acc: 0.9730\n",
      "Epoch 18/25\n",
      "21s - loss: 0.1193 - acc: 0.9786 - val_loss: 0.1420 - val_acc: 0.9588\n",
      "Epoch 19/25\n",
      "21s - loss: 0.0971 - acc: 0.9831 - val_loss: 0.0936 - val_acc: 0.9820\n",
      "Epoch 20/25\n",
      "21s - loss: 0.0837 - acc: 0.9852 - val_loss: 0.0801 - val_acc: 0.9846\n",
      "Epoch 21/25\n",
      "21s - loss: 0.0664 - acc: 0.9893 - val_loss: 0.0825 - val_acc: 0.9791\n",
      "Epoch 22/25\n",
      "21s - loss: 0.0559 - acc: 0.9913 - val_loss: 0.0573 - val_acc: 0.9892\n",
      "Epoch 23/25\n",
      "21s - loss: 0.0464 - acc: 0.9932 - val_loss: 0.0465 - val_acc: 0.9917\n",
      "Epoch 24/25\n",
      "21s - loss: 0.0485 - acc: 0.9905 - val_loss: 0.0586 - val_acc: 0.9865\n",
      "Epoch 25/25\n",
      "21s - loss: 0.0522 - acc: 0.9882 - val_loss: 0.0315 - val_acc: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1c58547160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=128, epochs=25, verbose=2, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# General case: different input and output sequence lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T14:57:47.951099Z",
     "start_time": "2017-10-15T09:19:21.935Z"
    }
   },
   "source": [
    "We will implement a basic character level sequence to sequence model. We apply it to translating short english sentences into short french sentences, character by character."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We start with input sequences from a domain and corresponding target sequences from another domain\n",
    "- An encoder LSTM turns input sequences to 2 state vectors (we keep the last LSTM state and discard the outputs)\n",
    "- A decoder LSTM is trained to turn the target sequences into the same sequence but offset by one timestep in the future, a training process called 'teacher forcing' in this context. It uses as initials state the state vectors from the encoder. Effectively, the decoder learns to generate  targets[t+1...] given targets[...t], conditioned on the input sequence\n",
    "- In the inference mode, we\n",
    "- Encode the input sequence into state vectors\n",
    "- Start with target sequence of size 1\n",
    "- Feed the state vectors and 1-char target sequence to the decoder to produce predictions for the next character\n",
    "- Sample the next character using these predictions\n",
    "- Append the sampled character to the target sequence\n",
    "- Repeat until we generate the end-of-sequence character or we hit the character limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:20.946289Z",
     "start_time": "2017-10-15T15:13:03.935607Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:20.981544Z",
     "start_time": "2017-10-15T15:13:20.978448Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_samples = 10000 # number of samples to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:21.229566Z",
     "start_time": "2017-10-15T15:13:21.016584Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vectorize the data\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "lines = open('./fra.txt').read().split('\\n')\n",
    "for line in lines[:min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # lets use tab as start sequence character and \\n as the end sequence character\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:21.943050Z",
     "start_time": "2017-10-15T15:13:21.927597Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.', 'Run!', 'Run!', 'Wow!', 'Fire!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:22.646405Z",
     "start_time": "2017-10-15T15:13:22.635044Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\tVa !\\n',\n",
       " '\\tCours\\u202f!\\n',\n",
       " '\\tCourez\\u202f!\\n',\n",
       " '\\tÇa alors\\u202f!\\n',\n",
       " '\\tAu feu !\\n']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:23.353054Z",
     "start_time": "2017-10-15T15:13:23.345581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:24.061932Z",
     "start_time": "2017-10-15T15:13:24.057556Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_encoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:24.762637Z",
     "start_time": "2017-10-15T15:13:24.758137Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_decoder_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:25.484633Z",
     "start_time": "2017-10-15T15:13:25.480241Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(char, i) for i,char in enumerate(input_characters)])\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:26.186713Z",
     "start_time": "2017-10-15T15:13:26.180539Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype = 'float32'\n",
    ")\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype = 'float32'\n",
    ")\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype = 'float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:13:27.355453Z",
     "start_time": "2017-10-15T15:13:27.011754Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_target_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:15:35.674607Z",
     "start_time": "2017-10-15T15:15:35.305334Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "encoder = LSTM(256, return_state = True)\n",
    "encoder_ouputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# we discard the output, and only keep the states\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:17:30.737101Z",
     "start_time": "2017-10-15T15:17:30.290468Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape = (None, num_decoder_tokens))\n",
    "decoder_lstm = LSTM(256, return_sequences = True, return_state = True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation = 'softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:17:48.469864Z",
     "start_time": "2017-10-15T15:17:48.463741Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:17:58.787581Z",
     "start_time": "2017-10-15T15:17:58.775603Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, None, 71)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, None, 93)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    [(None, 256), (None,  335872      input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    [(None, None, 256), ( 358400      input_2[0][0]                    \n",
      "                                                                   lstm_1[0][1]                     \n",
      "                                                                   lstm_1[0][2]                     \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, None, 93)      23901       lstm_2[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 718,173\n",
      "Trainable params: 718,173\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:52:37.540298Z",
     "start_time": "2017-10-15T15:25:06.662501Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/25\n",
      "66s - loss: 0.9291 - val_loss: 0.9799\n",
      "Epoch 2/25\n",
      "65s - loss: 0.7422 - val_loss: 0.8107\n",
      "Epoch 3/25\n",
      "66s - loss: 0.6306 - val_loss: 0.7294\n",
      "Epoch 4/25\n",
      "65s - loss: 0.5723 - val_loss: 0.6764\n",
      "Epoch 5/25\n",
      "65s - loss: 0.5323 - val_loss: 0.6465\n",
      "Epoch 6/25\n",
      "66s - loss: 0.4996 - val_loss: 0.6043\n",
      "Epoch 7/25\n",
      "66s - loss: 0.4724 - val_loss: 0.5884\n",
      "Epoch 8/25\n",
      "66s - loss: 0.4490 - val_loss: 0.5708\n",
      "Epoch 9/25\n",
      "65s - loss: 0.4297 - val_loss: 0.5610\n",
      "Epoch 10/25\n",
      "65s - loss: 0.4123 - val_loss: 0.5415\n",
      "Epoch 11/25\n",
      "65s - loss: 0.3970 - val_loss: 0.5306\n",
      "Epoch 12/25\n",
      "66s - loss: 0.3817 - val_loss: 0.5248\n",
      "Epoch 13/25\n",
      "65s - loss: 0.3683 - val_loss: 0.5152\n",
      "Epoch 14/25\n",
      "65s - loss: 0.3559 - val_loss: 0.5072\n",
      "Epoch 15/25\n",
      "65s - loss: 0.3442 - val_loss: 0.5010\n",
      "Epoch 16/25\n",
      "66s - loss: 0.3331 - val_loss: 0.4980\n",
      "Epoch 17/25\n",
      "65s - loss: 0.3229 - val_loss: 0.4919\n",
      "Epoch 18/25\n",
      "65s - loss: 0.3127 - val_loss: 0.4907\n",
      "Epoch 19/25\n",
      "65s - loss: 0.3033 - val_loss: 0.4879\n",
      "Epoch 20/25\n",
      "65s - loss: 0.2941 - val_loss: 0.4867\n",
      "Epoch 21/25\n",
      "66s - loss: 0.2855 - val_loss: 0.4899\n",
      "Epoch 22/25\n",
      "65s - loss: 0.2770 - val_loss: 0.4886\n",
      "Epoch 23/25\n",
      "65s - loss: 0.2692 - val_loss: 0.4849\n",
      "Epoch 24/25\n",
      "66s - loss: 0.2614 - val_loss: 0.4874\n",
      "Epoch 25/25\n",
      "66s - loss: 0.2541 - val_loss: 0.4859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd03bd8f400>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size = 64,\n",
    "          verbose = 2,\n",
    "          epochs = 25,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next: inference mode (sampling). Here's the drill:\n",
    "1. encode input and retrieve initial decoder state\n",
    "2. run one step of decoder with this initial state and a \"start of sequence\" token as target. Output will be the next target token\n",
    "3. Repeat with the current target token and current states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:52:58.067136Z",
     "start_time": "2017-10-15T15:52:57.899180Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:52:58.917533Z",
     "start_time": "2017-10-15T15:52:58.913292Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "(i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:52:59.945216Z",
     "start_time": "2017-10-15T15:52:59.915254Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-15T15:53:04.215950Z",
     "start_time": "2017-10-15T15:53:00.896652Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Allez chercher un manteille !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Toui le monde !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Toui le monde !\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Fais-le de coup de mainte.\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Donne-moi un bisa !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Appelle Tom !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Laissez-moi manner.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête de tortir !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête de tortir !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête de tortir !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je l'ai vu.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: Je l'ai contrarié.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: J'ai été pruvent.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: J'ai été pruvent.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Personne ne sent sout.\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attendez !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Prends une boule !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Prends une boule !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Prends une boule !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Prends une boule !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Sorte dan la mais !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Allous chez vous !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Allous chez vous !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Allous chez vous !\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Restez allon !\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Restez allon !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Merre-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Merre-moi !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je me suis sentie travailler.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je me suis sentie travailler.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je me suis sentie ancurée.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: J'aime le sien.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: J'aime le sien.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: J'aime le chercher.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: Je suis très fatiguée.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis connais.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je suis connais.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Laissez Tom esteille.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Personne ne s'est avant.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Personne ne s'est avant.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Personne ne s'est avant.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Personne ne s'est avant.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Personne ne s'est avant.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Personne ne s'est avant.\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: Personne ne s'est avant.\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Sarie le faire ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Sarie le faire ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Sarie le faire ?\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: C'était la vieux.\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: Nous sommes en train de manger.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous pouvons nous en aller.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous pouvons nous en aller.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous pouvons nous en aller.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous pouvons nous en aller.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Demande à qui que ce soit !\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: Comment ici !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: Sois prêt !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Sois confiant !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: Allez !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelle-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelle-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelle Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelle Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Venez à l'écherer.\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Venez à l'écherer.\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Venez à l'écherer.\n",
      "\n",
      "-\n",
      "Input sentence: Come in.\n",
      "Decoded sentence: Venez à l'écherer.\n",
      "\n",
      "-\n",
      "Input sentence: Come on!\n",
      "Decoded sentence: Venez à l'écaler.\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Viens chez moi.\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Viens chez moi.\n",
      "\n",
      "-\n",
      "Input sentence: Come on.\n",
      "Decoded sentence: Viens chez moi.\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-moi manter.\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-moi manter.\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-moi manter.\n",
      "\n",
      "-\n",
      "Input sentence: Drop it!\n",
      "Decoded sentence: Laissez-moi manter.\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Va chez moi !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Va chez moi !\n",
      "\n",
      "-\n",
      "Input sentence: Get out!\n",
      "Decoded sentence: Va chez moi !\n",
      "\n",
      "-\n",
      "Input sentence: Get out.\n",
      "Decoded sentence: Sors !\n",
      "\n",
      "-\n",
      "Input sentence: Get out.\n",
      "Decoded sentence: Sors !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training test)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
