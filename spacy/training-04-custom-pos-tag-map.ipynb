{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/explosion/spaCy/blob/master/LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple example for training a part-of-speech tagger with a custom tag map.\n",
    "To allow us to update the tag map with our custom one, this example starts off\n",
    "with a blank Language class and modifies its defaults. For more details, see\n",
    "the documentation:\n",
    "* Training: https://spacy.io/usage/training#section-tagger-parser\n",
    "* POS Tagging: https://spacy.io/usage/linguistic-features#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:34:20.390804Z",
     "start_time": "2018-04-30T11:34:20.124629Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:34:33.923737Z",
     "start_time": "2018-04-30T11:34:33.915932Z"
    }
   },
   "outputs": [],
   "source": [
    "# You need to define a mapping from your data's part-of-speech tag names to the\n",
    "# Universal Part-of-Speech tag set, as spaCy includes an enum of these tags.\n",
    "# See here for the Universal Tag Set:\n",
    "# http://universaldependencies.github.io/docs/u/pos/index.html\n",
    "# You may also specify morphological features for your tags, from the universal\n",
    "# scheme.\n",
    "TAG_MAP = {\n",
    "    'N': {'pos': 'NOUN'},\n",
    "    'V': {'pos': 'VERB'},\n",
    "    'J': {'pos': 'ADJ'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:34:55.515910Z",
     "start_time": "2018-04-30T11:34:55.509018Z"
    }
   },
   "outputs": [],
   "source": [
    "# Usually you'll read this in, of course. Data formats vary. Ensure your\n",
    "# strings are unicode and that the number of tags assigned matches spaCy's\n",
    "# tokenization. If not, you can always add a 'words' key to the annotations\n",
    "# that specifies the gold-standard tokenization, e.g.:\n",
    "# (\"Eatblueham\", {'words': ['Eat', 'blue', 'ham'] 'tags': ['V', 'J', 'N']})\n",
    "TRAIN_DATA = [\n",
    "    (\"I like green eggs\", {'tags': ['N', 'V', 'J', 'N']}),\n",
    "    (\"Eat blue ham\", {'tags': ['V', 'J', 'N']})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new model, set up the pipeline and train the tagger. In order to\n",
    "train the tagger with a custom tag map, we're creating a new Language\n",
    "instance with a custom vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:35:39.701771Z",
     "start_time": "2018-04-30T11:35:39.562808Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:36:43.334309Z",
     "start_time": "2018-04-30T11:36:43.331912Z"
    }
   },
   "outputs": [],
   "source": [
    "# add the tagger to the pipeline\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "tagger = nlp.create_pipe('tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:37:30.137639Z",
     "start_time": "2018-04-30T11:37:30.113771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add the tags. This needs to be done before you start training.\n",
    "for tag, values in TAG_MAP.items():\n",
    "    tagger.add_label(tag, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:37:34.396252Z",
     "start_time": "2018-04-30T11:37:34.389886Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:37:53.132010Z",
     "start_time": "2018-04-30T11:37:50.734965Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "{'tagger': 0.5731515735387802}\n",
      "{'tagger': 0.5486934930086136}\n",
      "{'tagger': 0.4483537822961807}\n",
      "{'tagger': 0.2599456459283829}\n",
      "{'tagger': 0.11532417312264442}\n",
      "{'tagger': 0.030577277764678}\n",
      "{'tagger': 0.0038234422099776566}\n",
      "{'tagger': 0.00029430676659103483}\n",
      "{'tagger': 3.885022488248069e-05}\n",
      "{'tagger': 5.859134262209409e-06}\n",
      "{'tagger': 1.3233649269750458e-06}\n",
      "{'tagger': 4.0967667302993505e-07}\n",
      "{'tagger': 1.5634972783118428e-07}\n",
      "{'tagger': 7.014039837827113e-08}\n",
      "{'tagger': 3.6199250708079944e-08}\n",
      "{'tagger': 2.043198144008329e-08}\n",
      "{'tagger': 1.296029239483687e-08}\n",
      "{'tagger': 8.569453147089234e-09}\n",
      "{'tagger': 6.100724370128319e-09}\n",
      "{'tagger': 4.687360499744386e-09}\n",
      "{'tagger': 3.618845445529928e-09}\n",
      "{'tagger': 3.0014332130789967e-09}\n",
      "{'tagger': 2.4642485829673433e-09}\n",
      "{'tagger': 2.155601586117939e-09}\n",
      "{'tagger': 1.872014654402676e-09}\n"
     ]
    }
   ],
   "source": [
    "optimizer = nlp.begin_training()\n",
    "for i in range(25):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        nlp.update([text], [annotations], sgd=optimizer, losses=losses)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:37:59.686169Z",
     "start_time": "2018-04-30T11:37:59.675662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tags [('I', 'N', 'NOUN'), ('like', 'V', 'VERB'), ('blue', 'J', 'ADJ'), ('eggs', 'N', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "# test the trained model\n",
    "test_text = \"I like blue eggs\"\n",
    "doc = nlp(test_text)\n",
    "print('Tags', [(t.text, t.tag_, t.pos_) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
