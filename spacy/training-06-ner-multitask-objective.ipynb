{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/explosion/spaCy/blob/master/LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to add a multi-task objective that is trained\n",
    "alongside the entity recognizer. This is an alternative to adding features\n",
    "to the model.\n",
    "\n",
    "The multi-task idea is to train an auxiliary model to predict some attribute,\n",
    "with weights shared between the auxiliary model and the main model. In this\n",
    "example, we're predicting the position of the word in the document.\n",
    "\n",
    "The model that predicts the position of the word encourages the convolutional\n",
    "layers to include the position information in their representation. The\n",
    "information is then available to the main model, as a feature.\n",
    "\n",
    "The overall idea is that we might know something about what sort of features\n",
    "we'd like the CNN to extract. The multi-task objectives can encourage the\n",
    "extraction of this type of feature. The multi-task objective is only used\n",
    "during training. We discard the auxiliary model before run-time.\n",
    "\n",
    "The specific example here is not necessarily a good idea --- but it shows\n",
    "how an arbitrary objective function for some word can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:49:47.239745Z",
     "start_time": "2018-04-30T11:49:46.987860Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import plac\n",
    "import spacy\n",
    "import os.path\n",
    "from spacy.gold import read_json_file, GoldParse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:49:47.403819Z",
     "start_time": "2018-04-30T11:49:47.398424Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:49:47.944382Z",
     "start_time": "2018-04-30T11:49:47.937898Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA = list(read_json_file('../data/training-data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:49:52.559213Z",
     "start_time": "2018-04-30T11:49:52.549672Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_position_label(i, words, tags, heads, labels, ents):\n",
    "    '''Return labels indicating the position of the word in the document.\n",
    "    '''\n",
    "    if len(words) < 20:\n",
    "        return 'short-doc'\n",
    "    elif i == 0:\n",
    "        return 'first-word'\n",
    "    elif i < 10:\n",
    "        return 'early-word'\n",
    "    elif i < 20:\n",
    "        return 'mid-word'\n",
    "    elif i == len(words)-1:\n",
    "        return 'last-word'\n",
    "    else:\n",
    "        return 'late-word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:49:56.437592Z",
     "start_time": "2018-04-30T11:49:56.303801Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank('en')\n",
    "ner = nlp.create_pipe('ner')\n",
    "ner.add_multitask_objective(get_position_label)\n",
    "nlp.add_pipe(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:49:59.962323Z",
     "start_time": "2018-04-30T11:49:57.996808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "0.0 38.86346965752\n",
      "0.0 25.92212019408212\n",
      "0.0 29.088292832429502\n",
      "0.0 21.533498413347996\n",
      "0.0 17.81456380731507\n",
      "0.0 17.797718213371915\n",
      "0.0 12.751342002763954\n",
      "0.0 14.553385668152174\n",
      "0.0 7.800720825029798\n",
      "0.0 7.32101260258942\n"
     ]
    }
   ],
   "source": [
    "optimizer = nlp.begin_training(get_gold_tuples=lambda: TRAIN_DATA)\n",
    "for itn in range(10):\n",
    "    random.shuffle(TRAIN_DATA)\n",
    "    losses = {}\n",
    "    for text, annot_brackets in TRAIN_DATA:\n",
    "        annotations, _ = annot_brackets\n",
    "        doc = nlp.make_doc(text)\n",
    "        gold = GoldParse.from_annot_tuples(doc, annotations[0])\n",
    "        nlp.update(\n",
    "            [doc],  # batch of texts\n",
    "            [gold],  # batch of annotations\n",
    "            drop=0.2,  # dropout - make it harder to memorise data\n",
    "            sgd=optimizer,  # callable to update weights\n",
    "            losses=losses)\n",
    "    print(losses.get('nn_labeller', 0.0), losses['ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T11:49:59.989101Z",
     "start_time": "2018-04-30T11:49:59.964487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities [('Oct. 19', 'DATE'), ('The Misanthrope', 'WORK_OF_ART'), ('Chicago', 'GPE'), ('Goodman Theatre', 'FAC'), ('Revitalized Classics Take the', 'WORK_OF_ART'), ('Leisure & Arts', 'ORG'), ('Celimene', 'PERSON'), ('Kim Cattrall', 'PERSON'), ('Christina Haag', 'PERSON')]\n",
      "Tokens [('In', '', 2), ('an', '', 2), ('Oct.', 'DATE', 3), ('19', 'DATE', 1), ('review', '', 2), ('of', '', 2), ('\"', '', 2), ('The', 'WORK_OF_ART', 3), ('Misanthrope', 'WORK_OF_ART', 1), ('\"', '', 2), ('at', '', 2), ('Chicago', 'GPE', 3), (\"'s\", '', 2), ('Goodman', 'FAC', 3), ('Theatre', 'FAC', 1), ('(', '', 2), ('\"', '', 2), ('Revitalized', 'WORK_OF_ART', 3), ('Classics', 'WORK_OF_ART', 1), ('Take', 'WORK_OF_ART', 1), ('the', 'WORK_OF_ART', 1), ('Stage', '', 2), ('in', '', 2), ('Windy', '', 2), ('City', '', 2), (',', '', 2), ('\"', '', 2), ('Leisure', 'ORG', 3), ('&', 'ORG', 1), ('Arts', 'ORG', 1), (')', '', 2), (',', '', 2), ('the', '', 2), ('role', '', 2), ('of', '', 2), ('Celimene', 'PERSON', 3), (',', '', 2), ('played', '', 2), ('by', '', 2), ('Kim', 'PERSON', 3), ('Cattrall', 'PERSON', 1), (',', '', 2), ('was', '', 2), ('mistakenly', '', 2), ('attributed', '', 2), ('to', '', 2), ('Christina', 'PERSON', 3), ('Haag', 'PERSON', 1), ('.', '', 2), ('Ms.', '', 2), ('Haag', '', 2), ('plays', '', 2), ('Elianti', '', 2), ('.', '', 2)]\n"
     ]
    }
   ],
   "source": [
    "for text, _ in TRAIN_DATA:\n",
    "    doc = nlp(text)\n",
    "    print('Entities', [(ent.text, ent.label_) for ent in doc.ents])\n",
    "    print('Tokens', [(t.text, t.ent_type_, t.ent_iob) for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
