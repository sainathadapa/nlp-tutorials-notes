{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of a spaCy v2.0 pipeline component that sets entity annotations\n",
    "based on list of single or multiple-word company names. Companies are\n",
    "labelled as ORG and their spans are merged into one token. Additionally,\n",
    "._.has_tech_org and ._.is_tech_org is set on the Doc/Span and Token\n",
    "respectively.\n",
    "\n",
    "* Custom pipeline components: https://spacy.io//usage/processing-pipelines#custom-components\n",
    "\n",
    "Compatible with: spaCy v2.0.0+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T12:02:56.293536Z",
     "start_time": "2018-04-30T12:02:56.002008Z"
    }
   },
   "outputs": [],
   "source": [
    "import plac\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Doc, Span, Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T12:02:56.353672Z",
     "start_time": "2018-04-30T12:02:56.294905Z"
    }
   },
   "outputs": [],
   "source": [
    "# For simplicity, we start off with only the blank English Language class\n",
    "# and no model or pre-defined pipeline loaded.\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T12:02:56.437364Z",
     "start_time": "2018-04-30T12:02:56.355216Z"
    }
   },
   "outputs": [],
   "source": [
    "companies = ['Alphabet Inc.', 'Google', 'Netflix', 'Apple']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T12:02:56.530378Z",
     "start_time": "2018-04-30T12:02:56.442117Z"
    }
   },
   "outputs": [],
   "source": [
    "class TechCompanyRecognizer(object):\n",
    "    \"\"\"Example of a spaCy v2.0 pipeline component that sets entity annotations\n",
    "    based on list of single or multiple-word company names. Companies are\n",
    "    labelled as ORG and their spans are merged into one token. Additionally,\n",
    "    ._.has_tech_org and ._.is_tech_org is set on the Doc/Span and Token\n",
    "    respectively.\"\"\"\n",
    "    name = 'tech_companies'  # component name, will show up in the pipeline\n",
    "\n",
    "    def __init__(self, nlp, companies=tuple(), label='ORG'):\n",
    "        \"\"\"Initialise the pipeline component. The shared nlp instance is used\n",
    "        to initialise the matcher with the shared vocab, get the label ID and\n",
    "        generate Doc objects as phrase match patterns.\n",
    "        \"\"\"\n",
    "        self.label = nlp.vocab.strings[label]  # get entity label ID\n",
    "\n",
    "        # Set up the PhraseMatcher – it can now take Doc objects as patterns,\n",
    "        # so even if the list of companies is long, it's very efficient\n",
    "        patterns = [nlp(org) for org in companies]\n",
    "        self.matcher = PhraseMatcher(nlp.vocab)\n",
    "        self.matcher.add('TECH_ORGS', None, *patterns)\n",
    "\n",
    "        # Register attribute on the Token. We'll be overwriting this based on\n",
    "        # the matches, so we're only setting a default value, not a getter.\n",
    "        Token.set_extension('is_tech_org', default=False)\n",
    "\n",
    "        # Register attributes on Doc and Span via a getter that checks if one of\n",
    "        # the contained tokens is set to is_tech_org == True.\n",
    "        Doc.set_extension('has_tech_org', getter=self.has_tech_org)\n",
    "        Span.set_extension('has_tech_org', getter=self.has_tech_org)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        \"\"\"Apply the pipeline component on a Doc object and modify it if matches\n",
    "        are found. Return the Doc, so it can be processed by the next component\n",
    "        in the pipeline, if available.\n",
    "        \"\"\"\n",
    "        matches = self.matcher(doc)\n",
    "        spans = []  # keep the spans for later so we can merge them afterwards\n",
    "        for _, start, end in matches:\n",
    "            # Generate Span representing the entity & set label\n",
    "            entity = Span(doc, start, end, label=self.label)\n",
    "            spans.append(entity)\n",
    "            # Set custom attribute on each token of the entity\n",
    "            for token in entity:\n",
    "                token._.set('is_tech_org', True)\n",
    "            # Overwrite doc.ents and add entity – be careful not to replace!\n",
    "            doc.ents = list(doc.ents) + [entity]\n",
    "        for span in spans:\n",
    "            # Iterate over all spans and merge them into one token. This is done\n",
    "            # after setting the entities – otherwise, it would cause mismatched\n",
    "            # indices!\n",
    "            span.merge()\n",
    "        return doc  # don't forget to return the Doc!\n",
    "\n",
    "    def has_tech_org(self, tokens):\n",
    "        \"\"\"Getter for Doc and Span attributes. Returns True if one of the tokens\n",
    "        is a tech org. Since the getter is only called when we access the\n",
    "        attribute, we can refer to the Token's 'is_tech_org' attribute here,\n",
    "        which is already set in the processing step.\"\"\"\n",
    "        return any([t._.get('is_tech_org') for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T12:02:56.655465Z",
     "start_time": "2018-04-30T12:02:56.535202Z"
    }
   },
   "outputs": [],
   "source": [
    "component = TechCompanyRecognizer(nlp, companies)  # initialise component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T12:02:56.770416Z",
     "start_time": "2018-04-30T12:02:56.660414Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(component, last=True)  # add last to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-30T12:02:56.861215Z",
     "start_time": "2018-04-30T12:02:56.774783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline ['tech_companies']\n",
      "Tokens ['Alphabet Inc.', 'is', 'the', 'company', 'behind', 'Google', '.']\n",
      "Doc has_tech_org True\n",
      "Token 0 is_tech_org True\n",
      "Token 1 is_tech_org False\n",
      "Entities [('Alphabet Inc.', 'ORG'), ('Google', 'ORG')]\n"
     ]
    }
   ],
   "source": [
    "text = \"Alphabet Inc. is the company behind Google.\"\n",
    "doc = nlp(text)\n",
    "print('Pipeline', nlp.pipe_names)  # pipeline contains component name\n",
    "print('Tokens', [t.text for t in doc])  # company names from the list are merged\n",
    "print('Doc has_tech_org', doc._.has_tech_org)  # Doc contains tech orgs\n",
    "print('Token 0 is_tech_org', doc[0]._.is_tech_org)  # \"Alphabet Inc.\" is a tech org\n",
    "print('Token 1 is_tech_org', doc[1]._.is_tech_org)  # \"is\" is not\n",
    "print('Entities', [(e.text, e.label_) for e in doc.ents])  # all orgs are entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
