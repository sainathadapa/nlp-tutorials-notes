{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to use an LSTM sentiment classification model trained using Keras in spaCy. spaCy splits the document into sentences, and each sentence is classified using the LSTM. The scores for the sentences are then aggregated to give the document score. This kind of hierarchical model is quite difficult in \"pure\" Keras or Tensorflow, but it's very effective. The Keras example on this dataset performs quite poorly, because it cuts off the documents so that they're a fixed size. This hurts review accuracy a lot, because people often summarise their rating in the final sentence\n",
    "\n",
    "Prerequisites:\n",
    "spacy download en_vectors_web_lg\n",
    "pip install keras==2.0.9\n",
    "\n",
    "Compatible with: spaCy v2.0.0+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:09:45.182712Z",
     "start_time": "2018-04-29T15:09:45.084014Z"
    }
   },
   "outputs": [],
   "source": [
    "import plac\n",
    "import random\n",
    "import pathlib\n",
    "import cytoolz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:09:47.007149Z",
     "start_time": "2018-04-29T15:09:46.009986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:09:48.067356Z",
     "start_time": "2018-04-29T15:09:48.005945Z"
    }
   },
   "outputs": [],
   "source": [
    "import thinc.extra.datasets\n",
    "from spacy.compat import pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:07.849002Z",
     "start_time": "2018-04-29T15:09:49.104016Z"
    }
   },
   "outputs": [],
   "source": [
    "imdb_data = thinc.extra.datasets.imdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:17.794936Z",
     "start_time": "2018-04-29T15:13:17.785212Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels = zip(*imdb_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:18.368663Z",
     "start_time": "2018-04-29T15:13:18.357688Z"
    }
   },
   "outputs": [],
   "source": [
    "dev_texts, dev_labels = zip(*imdb_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:18.772621Z",
     "start_time": "2018-04-29T15:13:18.761455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:19.217242Z",
     "start_time": "2018-04-29T15:13:19.213620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:19.631347Z",
     "start_time": "2018-04-29T15:13:19.626863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As I write this review in 2008, we are mired in a remake culture. Movie studios seem determined to ruin as many classic films as they can with thoroughly pointless updates including 'King Kong, 'The Wicker Man' and practically every film that ever starred Michael Caine. This lazy remake mentality is not a new phenomenon, however, as 'Dough for the Do-Do' proves. An entirely pointless colorized version of Bob Clampett's surreal masterpiece 'Porky in Wackyland', 'Dough for the Do-Do' sucks the life out of the original by splashing colour all over Clampett's original footage and adding some lame new footage overseen by Friz Freleng. Freleng was an entirely unsuitable director to be tampering with Clampett's source material, although in truth no director could hope to come close to Clampett's inspired insanity. Inevitably, then, 'Dough for the Do-Do' is nothing more than the raping of a classic with an appalling new title attached. For cartoon fans like myself, its equivalent to a colorization of 'Casablanca'.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:20.035764Z",
     "start_time": "2018-04-29T15:13:20.031808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:20.541123Z",
     "start_time": "2018-04-29T15:13:20.534315Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels = np.asarray(train_labels, dtype='int32')\n",
    "dev_labels = np.asarray(dev_labels, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:29.641026Z",
     "start_time": "2018-04-29T15:13:20.948172Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:29.646862Z",
     "start_time": "2018-04-29T15:13:29.643337Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:29.738288Z",
     "start_time": "2018-04-29T15:13:29.649356Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_embeddings(vocab):\n",
    "    return vocab.vectors.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:29.848017Z",
     "start_time": "2018-04-29T15:13:29.740057Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings = get_embeddings(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = list(nlp.pipe(train_texts, batch_size=10000, n_threads=48))\n",
    "dev_docs = list(nlp.pipe(dev_texts, batch_size=10000, n_threads=48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelled_sentences(docs, doc_labels):\n",
    "    labels = []\n",
    "    sentences = []\n",
    "    for doc, y in zip(docs, doc_labels):\n",
    "        for sent in doc.sents:\n",
    "            sentences.append(sent)\n",
    "            labels.append(y)\n",
    "    return sentences, np.asarray(labels, dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs, train_labels = get_labelled_sentences(train_docs, train_labels)\n",
    "dev_docs, dev_labels = get_labelled_sentences(dev_docs, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(docs, max_length):\n",
    "    docs = list(docs)\n",
    "    Xs = np.zeros((len(docs), max_length), dtype='int32')\n",
    "    for i, doc in enumerate(docs):\n",
    "        j = 0\n",
    "        for token in doc:\n",
    "            vector_id = token.vocab.vectors.find(key=token.orth)\n",
    "            if vector_id >= 0:\n",
    "                Xs[i, j] = vector_id\n",
    "            else:\n",
    "                Xs[i, j] = 0\n",
    "            j += 1\n",
    "            if j >= max_length:\n",
    "                break\n",
    "    return Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_shape = {'nr_hidden': 64, 'max_length': 100, 'nr_class': 1}\n",
    "lstm_settings = {'dropout': 0.5, 'lr': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = get_features(train_docs, lstm_shape['max_length'])\n",
    "dev_X = get_features(dev_docs, lstm_shape['max_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object((train_texts, train_labels, train_X), 'train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object((dev_texts, dev_labels, dev_X), 'dev.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plac\n",
    "import random\n",
    "import pathlib\n",
    "import cytoolz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import LSTM, Dense, Embedding, Bidirectional\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thinc.extra.datasets\n",
    "from spacy.compat import pickle\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.pkl', 'rb') as f:\n",
    "    train_texts, train_labels, train_X = pickle.load(f)\n",
    "with open('dev.pkl', 'rb') as f:\n",
    "    dev_texts, dev_labels, dev_X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_shape = {'nr_hidden': 64, 'max_length': 100, 'nr_class': 1}\n",
    "lstm_settings = {'dropout': 0.5, 'lr': 0.001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "def get_embeddings(vocab):\n",
    "    return vocab.vectors.data\n",
    "embeddings = get_embeddings(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:33.149462Z",
     "start_time": "2018-04-29T15:13:29.962741Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Embedding(\n",
    "        embeddings.shape[0],\n",
    "        embeddings.shape[1],\n",
    "        input_length=lstm_shape['max_length'],\n",
    "        trainable=False,\n",
    "        weights=[embeddings],\n",
    "        mask_zero=True\n",
    "    )\n",
    ")\n",
    "model.add(TimeDistributed(Dense(lstm_shape['nr_hidden'],\n",
    "                                use_bias=False)))\n",
    "model.add(Bidirectional(LSTM(lstm_shape['nr_hidden'],\n",
    "                             recurrent_dropout=lstm_settings['dropout'],\n",
    "                             dropout=lstm_settings['dropout'])))\n",
    "model.add(Dense(lstm_shape['nr_class'],\n",
    "                activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:33.196140Z",
     "start_time": "2018-04-29T15:13:33.151831Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=lstm_settings['lr']),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-29T15:13:33.265803Z",
     "start_time": "2018-04-29T15:13:33.198799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 300)          205449300 \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 100, 64)           19200     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 205,534,677\n",
      "Trainable params: 85,377\n",
      "Non-trainable params: 205,449,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-29T16:15:19.847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 310254 samples, validate on 304112 samples\n",
      "Epoch 1/5\n",
      " - 107s - loss: 0.6560 - acc: 0.6072 - val_loss: 0.6185 - val_acc: 0.6588\n",
      "Epoch 2/5\n",
      " - 103s - loss: 0.6156 - acc: 0.6623 - val_loss: 0.6033 - val_acc: 0.6745\n",
      "Epoch 3/5\n",
      " - 103s - loss: 0.6040 - acc: 0.6727 - val_loss: 0.5951 - val_acc: 0.6803\n",
      "Epoch 4/5\n",
      " - 103s - loss: 0.5969 - acc: 0.6777 - val_loss: 0.5955 - val_acc: 0.6791\n",
      "Epoch 5/5\n",
      " - 103s - loss: 0.5937 - acc: 0.6794 - val_loss: 0.5872 - val_acc: 0.6848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f36caf0c518>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X,\n",
    "          train_labels,\n",
    "          validation_data=(dev_X, dev_labels),\n",
    "          epochs=5,\n",
    "          batch_size=10000,\n",
    "          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
